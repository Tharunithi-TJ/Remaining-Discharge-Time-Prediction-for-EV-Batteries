{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhHxYpugoTCk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# List to store standard deviations and filenames\n",
        "std_devs = []\n",
        "\n",
        "# Loop over each CSV file\n",
        "for file in glob.glob(\"/content/B*.csv\"):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file)\n",
        "\n",
        "    # Calculate the standard deviation of the SOH column\n",
        "    soh_std = df['SOH'].std()\n",
        "\n",
        "    # Append to the list as a tuple of (filename, standard deviation)\n",
        "    std_devs.append((file, soh_std))\n",
        "\n",
        "# Sort the list based on the standard deviation\n",
        "sorted_files = sorted(std_devs, key=lambda x: x[1])\n",
        "\n",
        "# Display sorted results\n",
        "for file, std in sorted_files:\n",
        "    print(f\"{file}: {std}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKJdmBWT7vqn",
        "outputId": "24425e1f-b202-4461-9720-25bea06f9707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/B08.csv: 0.052853774130194354\n",
            "/content/B06.csv: 0.07637558811806872\n",
            "/content/B01.csv: 0.07821332845010749\n",
            "/content/B03.csv: 0.09118976390970092\n",
            "/content/B05.csv: 0.11001056381720095\n",
            "/content/B07.csv: 0.11342750770012151\n",
            "/content/B04.csv: 0.11575905639306033\n",
            "/content/B02.csv: 0.13679096477364597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "files_to_concat = ['/content/B08.csv', '/content/B05.csv', '/content/B02.csv']\n",
        "\n",
        "# Read and concatenate the files\n",
        "concatenated_df = pd.concat([pd.read_csv(file) for file in files_to_concat], ignore_index=True)\n",
        "# Save the concatenated DataFrame to a file in Colab's virtual environment\n",
        "save_path = \"/content/concatenated_df.csv\"\n",
        "concatenated_df.to_csv(save_path, index=False)\n",
        "\n",
        "# Download the file to your local machine\n",
        "from google.colab import files\n",
        "files.download(save_path)\n",
        "\n",
        "# Display the concatenated DataFrame\n",
        "print(concatenated_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "H3cYyWMC78vH",
        "outputId": "23646622-a328-4645-ffe4-9cee4d274d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac2f9019-83a6-4e6c-8a93-000781db65aa\", \"concatenated_df.csv\", 9902880)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        terminal_voltage  terminal_current  temperature  charge_current  \\\n",
            "0               3.854275         -0.004909    23.620648          0.0000   \n",
            "1               3.854246         -0.002896    23.620515          0.0002   \n",
            "2               3.174256         -4.026186    23.693978          4.0000   \n",
            "3               3.134106         -4.027110    23.947843          4.0000   \n",
            "4               3.098808         -4.027657    24.323838          4.0000   \n",
            "...                  ...               ...          ...             ...   \n",
            "118644          3.700989         -0.004594    28.979655          0.0004   \n",
            "118645          3.700967         -0.000881    28.905148          0.0004   \n",
            "118646          3.701200         -0.002798    28.822990          0.0004   \n",
            "118647          3.701104         -0.003812    28.757153          0.0004   \n",
            "118648          3.701049         -0.003201    28.679696          0.0006   \n",
            "\n",
            "        charge_voltage      time  capacity  cycle       SOH  \n",
            "0                0.000     0.000  0.745930      1  0.372965  \n",
            "1                3.868     9.328  0.745930      1  0.372965  \n",
            "2                1.284    19.421  0.745930      1  0.372965  \n",
            "3                1.247    28.750  0.745930      1  0.372965  \n",
            "4                1.213    38.125  0.745930      1  0.372965  \n",
            "...                ...       ...       ...    ...       ...  \n",
            "118644           0.000  2765.329  1.315283    197  0.657641  \n",
            "118645           0.000  2781.407  1.315283    197  0.657641  \n",
            "118646           0.000  2797.454  1.315283    197  0.657641  \n",
            "118647           0.000  2813.469  1.315283    197  0.657641  \n",
            "118648           0.000  2829.516  1.315283    197  0.657641  \n",
            "\n",
            "[118649 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=concatenated_df\n",
        "print(df.head())\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F09k0esoXhc",
        "outputId": "c0bad821-b5ef-4902-bb42-157cec28de6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   terminal_voltage  terminal_current  temperature  charge_current  \\\n",
            "0          3.854275         -0.004909    23.620648          0.0000   \n",
            "1          3.854246         -0.002896    23.620515          0.0002   \n",
            "2          3.174256         -4.026186    23.693978          4.0000   \n",
            "3          3.134106         -4.027110    23.947843          4.0000   \n",
            "4          3.098808         -4.027657    24.323838          4.0000   \n",
            "\n",
            "   charge_voltage    time  capacity  cycle       SOH  \n",
            "0           0.000   0.000   0.74593      1  0.372965  \n",
            "1           3.868   9.328   0.74593      1  0.372965  \n",
            "2           1.284  19.421   0.74593      1  0.372965  \n",
            "3           1.247  28.750   0.74593      1  0.372965  \n",
            "4           1.213  38.125   0.74593      1  0.372965  \n",
            "(118649, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "input_vars = ['terminal_voltage', 'terminal_current', 'temperature', 'charge_current', 'charge_voltage', 'time', 'capacity', 'cycle']\n",
        "output_var = 'SOH'\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_input = train[input_vars]\n",
        "train_output = train[output_var]\n",
        "test_input = test[input_vars]\n",
        "test_output = test[output_var]\n",
        "\n",
        "\n",
        "# Define the Kalman filter model\n",
        "class KalmanFilter(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(KalmanFilter, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.F = nn.Parameter(torch.eye(dim))\n",
        "        self.H = nn.Parameter(torch.eye(dim))\n",
        "        self.Q = nn.Parameter(torch.eye(dim))\n",
        "        self.R = nn.Parameter(torch.eye(dim))\n",
        "        self.x_prior = nn.Parameter(torch.zeros(dim))\n",
        "        self.P_prior = nn.Parameter(torch.eye(dim))\n",
        "\n",
        "    def forward(self, z):\n",
        "        # Prediction step\n",
        "        x_prior = torch.matmul(self.F, self.x_prior.data)\n",
        "        P_prior = torch.matmul(torch.matmul(self.F, self.P_prior), self.F.transpose(0, 1)) + self.Q\n",
        "\n",
        "        # Update step\n",
        "        HPHtR = torch.matmul(self.H, torch.matmul(P_prior, self.H.transpose(0, 1))) + self.R + 1e-8 * torch.eye(self.dim)\n",
        "        K = torch.matmul(torch.matmul(P_prior, self.H.transpose(0, 1)), torch.inverse(HPHtR))\n",
        "        x_posterior = x_prior + torch.matmul(K, z - torch.matmul(self.H, x_prior))\n",
        "        P_posterior = torch.matmul(torch.eye(self.dim) - torch.matmul(K, self.H), P_prior)\n",
        "\n",
        "        self.x_prior.data = x_posterior\n",
        "        self.P_prior.data = P_posterior\n",
        "\n",
        "        return x_posterior\n",
        "\n",
        "# Initialize the model and perform training\n",
        "model = KalmanFilter(dim=len(input_vars))\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    for i in range(len(train_input)):\n",
        "        input_tensor = torch.tensor(train_input.values[i], dtype=torch.float32)\n",
        "        output_tensor = torch.tensor(train_output.values[i], dtype=torch.float32)\n",
        "\n",
        "        output = model(input_tensor)\n",
        "        loss = criterion(output, output_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        train_loss += loss.item()\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss/len(train_input)))\n",
        "\n",
        "# Perform testing and print the mean squared error\n",
        "test_loss = 0.0\n",
        "for i in range(len(test_input)):\n",
        "    input_tensor = torch.tensor(test_input.values[i], dtype=torch.float32)\n",
        "    output_tensor = torch.tensor(test_output.values[i], dtype=torch.float32)\n",
        "    output = model(input_tensor)\n",
        "    loss = criterion(output, output_tensor)\n",
        "    test_loss += loss.item()\n",
        "print('Test Loss: {:.6f}'.format(test_loss/len(test_input)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWiqtg6epGtb",
        "outputId": "36525385-adf1-49ba-ccca-535d31908a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 401.391516\n",
            "Epoch: 2 \tTraining Loss: 0.000962\n",
            "Epoch: 3 \tTraining Loss: 0.000267\n",
            "Epoch: 4 \tTraining Loss: 0.000111\n",
            "Epoch: 5 \tTraining Loss: 0.000062\n",
            "Epoch: 6 \tTraining Loss: 0.000041\n",
            "Epoch: 7 \tTraining Loss: 0.000034\n",
            "Epoch: 8 \tTraining Loss: 0.000028\n",
            "Epoch: 9 \tTraining Loss: 0.000019\n",
            "Epoch: 10 \tTraining Loss: 0.000017\n",
            "Test Loss: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select an initial index from the test set to start predictions\n",
        "initial_index = 10000  # change as desired\n",
        "predictions = []\n",
        "actual_values = []\n",
        "\n",
        "# Use the initial input state from the test set\n",
        "state = torch.tensor(test_input.values[initial_index], dtype=torch.float32)\n",
        "\n",
        "# Generate 10 continuous predictions using the actual state each time\n",
        "for step in range(10):\n",
        "    # Perform prediction\n",
        "    predicted_soh = model(state)\n",
        "\n",
        "    # Assuming SOH is the last element in predicted_soh, extract it\n",
        "    soh_value = predicted_soh[-1].item()  # adjust index if needed\n",
        "\n",
        "    # Store the prediction and actual values\n",
        "    predictions.append(soh_value)\n",
        "    actual_values.append(test_output.values[initial_index + step] if initial_index + step < len(test_output) else None)\n",
        "\n",
        "    # Update the state: use the actual next state from the test input\n",
        "    if initial_index + step + 1 < len(test_input):\n",
        "        state = torch.tensor(test_input.values[initial_index + step + 1], dtype=torch.float32)\n",
        "\n",
        "# Print results\n",
        "print(\"Step\\tPredicted SOH\\tActual SOH\")\n",
        "for step in range(10):\n",
        "    actual = actual_values[step] if actual_values[step] is not None else \"N/A\"\n",
        "    print(f\"{step+1}\\t{predictions[step]:.6f}\\t\\t{actual}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oisdo_EpKDd7",
        "outputId": "2be6e8cd-ed35-4df1-d08b-38dd6490d778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step\tPredicted SOH\tActual SOH\n",
            "1\t0.831337\t\t0.831160858\n",
            "2\t0.676454\t\t0.676475209\n",
            "3\t0.829125\t\t0.82899779\n",
            "4\t0.674398\t\t0.674379944\n",
            "5\t0.817587\t\t0.817406499\n",
            "6\t0.785718\t\t0.785565168\n",
            "7\t0.790315\t\t0.790126501\n",
            "8\t0.680961\t\t0.680843254\n",
            "9\t0.806429\t\t0.806268056\n",
            "10\t0.696164\t\t0.696275605\n"
          ]
        }
      ]
    }
  ]
}